{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_treino = pd.read_csv(r\"D:\\pipeline_dados\\data_raw\\base_orcamentos_treino.csv\")\n",
    "x_teste_df = pd.read_csv(r\"D:\\pipeline_dados\\base_orcamentos_nov.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2023-11-01\n",
       "1      2023-11-01\n",
       "2      2023-11-01\n",
       "3      2023-11-01\n",
       "4      2023-11-01\n",
       "          ...    \n",
       "235    2023-11-24\n",
       "236    2023-11-24\n",
       "237    2023-11-24\n",
       "238    2023-11-24\n",
       "239    2023-11-24\n",
       "Name: dt_criacao, Length: 240, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna: dias_desejo, Variancia: 598.4518131101813\n",
      "Coluna: dias_em_casa, Variancia: 42.13326359832636\n",
      "Coluna: revestimento, Variancia: 4.744612970711297\n",
      "Coluna: officina, Variancia: 3.510460251046025\n",
      "Coluna: loucas_metais, Variancia: 34.26316248256626\n",
      "Coluna: arg_rejunte, Variancia: 10.29984309623431\n",
      "Coluna: categ_outros, Variancia: 0.0\n",
      "Coluna: vl_frete, Variancia: 1360312.4981384657\n",
      "Coluna: vlr_orcamento, Variancia: 324498673.25825137\n",
      "Coluna: convertidos, Variancia: 22982.67557531381\n",
      "Coluna: nao_convertidos, Variancia: 26247.837499999998\n"
     ]
    }
   ],
   "source": [
    "for i in range(x_teste_df.shape[1]):\n",
    "    col_name = x_teste_df.columns[i]\n",
    "    \n",
    "    if np.issubdtype(x_teste_df.iloc[:, i].dtype, np.number):\n",
    "        col_variance = x_teste_df.iloc[:, i].var()\n",
    "        print(f\"Coluna: {col_name}, Variancia: {col_variance}\")\n",
    "    else:\n",
    "        pass\n",
    "        #print(f\"Coluna: {col_name} nao Ã© numerico...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=26247.837499999998.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\pipeline_dados\\algoritmo_portobello\\classificacao_tensorflow.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/pipeline_dados/algoritmo_portobello/classificacao_tensorflow.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m selecao \u001b[39m=\u001b[39m VarianceThreshold(threshold\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/pipeline_dados/algoritmo_portobello/classificacao_tensorflow.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_selecao_variancia \u001b[39m=\u001b[39m selecao\u001b[39m.\u001b[39;49mfit_transform(col_variance)\n",
      "File \u001b[1;32md:\\pipeline_dados\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32md:\\pipeline_dados\\venv\\lib\\site-packages\\sklearn\\base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    915\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    917\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    918\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32md:\\pipeline_dados\\venv\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\pipeline_dados\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_variance_threshold.py:99\u001b[0m, in \u001b[0;36mVarianceThreshold.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     82\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Learn empirical variances from X.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \n\u001b[0;32m     84\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    100\u001b[0m         X,\n\u001b[0;32m    101\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    102\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[0;32m    103\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    104\u001b[0m     )\n\u001b[0;32m    106\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m):  \u001b[39m# sparse matrix\u001b[39;00m\n\u001b[0;32m    107\u001b[0m         _, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariances_ \u001b[39m=\u001b[39m mean_variance_axis(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32md:\\pipeline_dados\\venv\\lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    606\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32md:\\pipeline_dados\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:930\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[39mif\u001b[39;00m ensure_2d:\n\u001b[0;32m    928\u001b[0m     \u001b[39m# If input is scalar raise error\u001b[39;00m\n\u001b[0;32m    929\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 930\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    931\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got scalar array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    932\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    936\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=26247.837499999998.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "selecao = VarianceThreshold(threshold=5)\n",
    "X_selecao_variancia = selecao.fit_transform(col_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste = x_teste_df['convertido']\n",
    "x_teste_df = x_teste_df.drop(['convertido', 'id_quote'], axis=1)\n",
    "\n",
    "categoricos = ['ds_tipo_obra', 'nm_prop_oportunidade', 'proprietario', 'promocional', 'tipo_loja',\n",
    "               'banheiro', 'toda_casa', 'cozinha', 'area_externa', 'itens_assentamento', 'sala',\n",
    "               'piscina', 'area_servico', 'garagem', 'dormitorio', 'varanda', 'escada', 'amb_outros']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_teste_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing date column: dt_criacao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pipeline_dados\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:228: UserWarning: Found unknown categories in columns [1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "date_column = 'dt_criacao'\n",
    "\n",
    "if date_column in base_treino.columns:\n",
    "    print(f\"Removing date column: {date_column}\")\n",
    "    base_treino = base_treino.drop(date_column, axis=1, errors='ignore')\n",
    "    if date_column in categoricos:\n",
    "        categoricos.remove(date_column)\n",
    "else:\n",
    "    print(f\"Date column '{date_column}' not found in the training data.\")\n",
    "\n",
    "if date_column in x_teste_df.columns:\n",
    "    x_teste_df = x_teste_df.drop(date_column, axis=1, errors='ignore')\n",
    "    if date_column in categoricos:\n",
    "        categoricos.remove(date_column)\n",
    "else:\n",
    "    print(f\"Date column '{date_column}' not found in the test data.\")\n",
    "\n",
    "X = base_treino.drop(['convertido'], axis=1, errors='ignore')\n",
    "y = base_treino['convertido']\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "encoder = OneHotEncoder(drop='if_binary', handle_unknown='ignore')\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(X[categoricos]).toarray(),\n",
    "                          columns=encoder.get_feature_names_out(categoricos))\n",
    "\n",
    "X_final = pd.concat([X.drop(categoricos, axis=1), X_encoded], axis=1)\n",
    "\n",
    "X_test_encoded = pd.DataFrame(encoder.transform(x_teste_df[categoricos]).toarray(),\n",
    "                               columns=encoder.get_feature_names_out(categoricos))\n",
    "X_test_final = pd.concat([x_teste_df.drop('id_quote', axis=1, errors='ignore'), X_test_encoded], axis=1).drop(categoricos, axis=1).fillna(0)\n",
    "\n",
    "X = X.select_dtypes(exclude=['datetime64[ns]']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = X_final.select_dtypes(include=[np.number]).columns\n",
    "var_threshold = 0.15\n",
    "selector = VarianceThreshold(threshold=var_threshold)\n",
    "X_high_variance = selector.fit_transform(X_final[numeric_columns])\n",
    "\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "X_resampled = X_high_variance\n",
    "X_test_final = X_test_final.iloc[:, selected_feature_indices]\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_resampled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_resampled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "classifier.add(tf.keras.layers.Dense(units=400, activation='relu', input_shape=(len(X_resampled[0]),)))\n",
    "classifier.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "classifier.add(tf.keras.layers.Dense(units=400, activation='relu'))\n",
    "classifier.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "classifier.add(tf.keras.layers.Dense(units=200, activation='relu'))\n",
    "classifier.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "classifier.add(tf.keras.layers.Dense(units=200, activation='relu'))\n",
    "classifier.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "classifier.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
    "classifier.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "classifier.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "classifier.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 400)               6800      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 400)               160400    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 200)               80200     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 307801 (1.17 MB)\n",
      "Trainable params: 307801 (1.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='Adam', loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "179/179 [==============================] - 2s 4ms/step - loss: 21.3227 - accuracy: 0.5367\n",
      "Epoch 2/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 3.7772 - accuracy: 0.5641\n",
      "Epoch 3/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 1.1843 - accuracy: 0.5704\n",
      "Epoch 4/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.8988 - accuracy: 0.5930\n",
      "Epoch 5/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.7173 - accuracy: 0.5835\n",
      "Epoch 6/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.7551 - accuracy: 0.5814\n",
      "Epoch 7/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6987 - accuracy: 0.5844\n",
      "Epoch 8/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.7019 - accuracy: 0.6120\n",
      "Epoch 9/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6795 - accuracy: 0.6026\n",
      "Epoch 10/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6676 - accuracy: 0.6122\n",
      "Epoch 11/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6659 - accuracy: 0.6227\n",
      "Epoch 12/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6667 - accuracy: 0.6342\n",
      "Epoch 13/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6662 - accuracy: 0.6279\n",
      "Epoch 14/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6596 - accuracy: 0.6314\n",
      "Epoch 15/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6528 - accuracy: 0.6309\n",
      "Epoch 16/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6533 - accuracy: 0.6384\n",
      "Epoch 17/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6572 - accuracy: 0.6433\n",
      "Epoch 18/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6612 - accuracy: 0.6386\n",
      "Epoch 19/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6474 - accuracy: 0.6473\n",
      "Epoch 20/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6540 - accuracy: 0.6396\n",
      "Epoch 21/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6514 - accuracy: 0.6463\n",
      "Epoch 22/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6555 - accuracy: 0.6402\n",
      "Epoch 23/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6434 - accuracy: 0.6484\n",
      "Epoch 24/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6518 - accuracy: 0.6430\n",
      "Epoch 25/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6407 - accuracy: 0.6473\n",
      "Epoch 26/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6398 - accuracy: 0.6468\n",
      "Epoch 27/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6402 - accuracy: 0.6485\n",
      "Epoch 28/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6415 - accuracy: 0.6498\n",
      "Epoch 29/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6367 - accuracy: 0.6485\n",
      "Epoch 30/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6391 - accuracy: 0.6484\n",
      "Epoch 31/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6398 - accuracy: 0.6503\n",
      "Epoch 32/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6513 - accuracy: 0.6475\n",
      "Epoch 33/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6402 - accuracy: 0.6520\n",
      "Epoch 34/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6431 - accuracy: 0.6491\n",
      "Epoch 35/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6421 - accuracy: 0.6513\n",
      "Epoch 36/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6458 - accuracy: 0.6445\n",
      "Epoch 37/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6488 - accuracy: 0.6531\n",
      "Epoch 38/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6400 - accuracy: 0.6541\n",
      "Epoch 39/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6338 - accuracy: 0.6566\n",
      "Epoch 40/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6285 - accuracy: 0.6594\n",
      "Epoch 41/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6323 - accuracy: 0.6566\n",
      "Epoch 42/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6305 - accuracy: 0.6611\n",
      "Epoch 43/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6322 - accuracy: 0.6573\n",
      "Epoch 44/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6311 - accuracy: 0.6562\n",
      "Epoch 45/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6333 - accuracy: 0.6578\n",
      "Epoch 46/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6344 - accuracy: 0.6568\n",
      "Epoch 47/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6350 - accuracy: 0.6597\n",
      "Epoch 48/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6333 - accuracy: 0.6498\n",
      "Epoch 49/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6275 - accuracy: 0.6627\n",
      "Epoch 50/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6355 - accuracy: 0.6541\n",
      "Epoch 51/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6324 - accuracy: 0.6580\n",
      "Epoch 52/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6285 - accuracy: 0.6576\n",
      "Epoch 53/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6368 - accuracy: 0.6583\n",
      "Epoch 54/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6289 - accuracy: 0.6583\n",
      "Epoch 55/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6261 - accuracy: 0.6634\n",
      "Epoch 56/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6276 - accuracy: 0.6606\n",
      "Epoch 57/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6286 - accuracy: 0.6618\n",
      "Epoch 58/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6249 - accuracy: 0.6662\n",
      "Epoch 59/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6397 - accuracy: 0.6555\n",
      "Epoch 60/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6394 - accuracy: 0.6608\n",
      "Epoch 61/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6318 - accuracy: 0.6615\n",
      "Epoch 62/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6304 - accuracy: 0.6617\n",
      "Epoch 63/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6266 - accuracy: 0.6636\n",
      "Epoch 64/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6281 - accuracy: 0.6629\n",
      "Epoch 65/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6297 - accuracy: 0.6624\n",
      "Epoch 66/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6293 - accuracy: 0.6643\n",
      "Epoch 67/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6295 - accuracy: 0.6624\n",
      "Epoch 68/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6262 - accuracy: 0.6618\n",
      "Epoch 69/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.7863 - accuracy: 0.6576\n",
      "Epoch 70/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6425 - accuracy: 0.6583\n",
      "Epoch 71/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6301 - accuracy: 0.6568\n",
      "Epoch 72/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6304 - accuracy: 0.6585\n",
      "Epoch 73/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6450 - accuracy: 0.6505\n",
      "Epoch 74/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6310 - accuracy: 0.6578\n",
      "Epoch 75/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6261 - accuracy: 0.6627\n",
      "Epoch 76/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6209 - accuracy: 0.6660\n",
      "Epoch 77/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6302 - accuracy: 0.6561\n",
      "Epoch 78/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6275 - accuracy: 0.6641\n",
      "Epoch 79/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6310 - accuracy: 0.6606\n",
      "Epoch 80/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6373 - accuracy: 0.6597\n",
      "Epoch 81/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6313 - accuracy: 0.6634\n",
      "Epoch 82/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6450 - accuracy: 0.6638\n",
      "Epoch 83/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6281 - accuracy: 0.6631\n",
      "Epoch 84/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6240 - accuracy: 0.6645\n",
      "Epoch 85/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6224 - accuracy: 0.6697\n",
      "Epoch 86/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6211 - accuracy: 0.6711\n",
      "Epoch 87/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6291 - accuracy: 0.6629\n",
      "Epoch 88/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6247 - accuracy: 0.6664\n",
      "Epoch 89/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6243 - accuracy: 0.6634\n",
      "Epoch 90/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6243 - accuracy: 0.6679\n",
      "Epoch 91/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6279 - accuracy: 0.6606\n",
      "Epoch 92/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6227 - accuracy: 0.6676\n",
      "Epoch 93/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6228 - accuracy: 0.6672\n",
      "Epoch 94/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6241 - accuracy: 0.6723\n",
      "Epoch 95/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6215 - accuracy: 0.6741\n",
      "Epoch 96/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6235 - accuracy: 0.6659\n",
      "Epoch 97/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.6669\n",
      "Epoch 98/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6273 - accuracy: 0.6634\n",
      "Epoch 99/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6241 - accuracy: 0.6700\n",
      "Epoch 100/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6219 - accuracy: 0.6664\n",
      "Epoch 101/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6245 - accuracy: 0.6664\n",
      "Epoch 102/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6208 - accuracy: 0.6672\n",
      "Epoch 103/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6193 - accuracy: 0.6732\n",
      "Epoch 104/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6195 - accuracy: 0.6676\n",
      "Epoch 105/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6229 - accuracy: 0.6686\n",
      "Epoch 106/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6183 - accuracy: 0.6713\n",
      "Epoch 107/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6138 - accuracy: 0.6718\n",
      "Epoch 108/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6183 - accuracy: 0.6688\n",
      "Epoch 109/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6228 - accuracy: 0.6709\n",
      "Epoch 110/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6218 - accuracy: 0.6688\n",
      "Epoch 111/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6170 - accuracy: 0.6734\n",
      "Epoch 112/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6172 - accuracy: 0.6748\n",
      "Epoch 113/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6302 - accuracy: 0.6653\n",
      "Epoch 114/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6291 - accuracy: 0.6709\n",
      "Epoch 115/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6152 - accuracy: 0.6749\n",
      "Epoch 116/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6287 - accuracy: 0.6676\n",
      "Epoch 117/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6189 - accuracy: 0.6692\n",
      "Epoch 118/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6180 - accuracy: 0.6807\n",
      "Epoch 119/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6161 - accuracy: 0.6748\n",
      "Epoch 120/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6176 - accuracy: 0.6693\n",
      "Epoch 121/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6168 - accuracy: 0.6711\n",
      "Epoch 122/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6165 - accuracy: 0.6760\n",
      "Epoch 123/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6175 - accuracy: 0.6713\n",
      "Epoch 124/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6150 - accuracy: 0.6797\n",
      "Epoch 125/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6183 - accuracy: 0.6758\n",
      "Epoch 126/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6108 - accuracy: 0.6781\n",
      "Epoch 127/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6157 - accuracy: 0.6697\n",
      "Epoch 128/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6194 - accuracy: 0.6730\n",
      "Epoch 129/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6159 - accuracy: 0.6737\n",
      "Epoch 130/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6124 - accuracy: 0.6758\n",
      "Epoch 131/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6131 - accuracy: 0.6742\n",
      "Epoch 132/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6239 - accuracy: 0.6753\n",
      "Epoch 133/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6188 - accuracy: 0.6671\n",
      "Epoch 134/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6142 - accuracy: 0.6725\n",
      "Epoch 135/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6104 - accuracy: 0.6816\n",
      "Epoch 136/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6152 - accuracy: 0.6728\n",
      "Epoch 137/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6216 - accuracy: 0.6765\n",
      "Epoch 138/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6180 - accuracy: 0.6786\n",
      "Epoch 139/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6113 - accuracy: 0.6770\n",
      "Epoch 140/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6175 - accuracy: 0.6765\n",
      "Epoch 141/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6120 - accuracy: 0.6786\n",
      "Epoch 142/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6069 - accuracy: 0.6805\n",
      "Epoch 143/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6246 - accuracy: 0.6811\n",
      "Epoch 144/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6080 - accuracy: 0.6793\n",
      "Epoch 145/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6136 - accuracy: 0.6791\n",
      "Epoch 146/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6118 - accuracy: 0.6739\n",
      "Epoch 147/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6095 - accuracy: 0.6746\n",
      "Epoch 148/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6321 - accuracy: 0.6748\n",
      "Epoch 149/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6196 - accuracy: 0.6699\n",
      "Epoch 150/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6111 - accuracy: 0.6798\n",
      "Epoch 151/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6287 - accuracy: 0.6791\n",
      "Epoch 152/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6111 - accuracy: 0.6746\n",
      "Epoch 153/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6128 - accuracy: 0.6762\n",
      "Epoch 154/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6109 - accuracy: 0.6823\n",
      "Epoch 155/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6459 - accuracy: 0.6790\n",
      "Epoch 156/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.7967 - accuracy: 0.6732\n",
      "Epoch 157/200\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.6131 - accuracy: 0.6749\n",
      "Epoch 158/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6130 - accuracy: 0.6802\n",
      "Epoch 159/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6083 - accuracy: 0.6798\n",
      "Epoch 160/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6092 - accuracy: 0.6793\n",
      "Epoch 161/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6053 - accuracy: 0.6844\n",
      "Epoch 162/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6046 - accuracy: 0.6819\n",
      "Epoch 163/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6042 - accuracy: 0.6852\n",
      "Epoch 164/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6106 - accuracy: 0.6870\n",
      "Epoch 165/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6065 - accuracy: 0.6751\n",
      "Epoch 166/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6071 - accuracy: 0.6762\n",
      "Epoch 167/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6074 - accuracy: 0.6833\n",
      "Epoch 168/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6068 - accuracy: 0.6793\n",
      "Epoch 169/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6051 - accuracy: 0.6784\n",
      "Epoch 170/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5997 - accuracy: 0.6889\n",
      "Epoch 171/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6199 - accuracy: 0.6779\n",
      "Epoch 172/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6114 - accuracy: 0.6765\n",
      "Epoch 173/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6069 - accuracy: 0.6777\n",
      "Epoch 174/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6083 - accuracy: 0.6755\n",
      "Epoch 175/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6127 - accuracy: 0.6735\n",
      "Epoch 176/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6217 - accuracy: 0.6814\n",
      "Epoch 177/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6160 - accuracy: 0.6798\n",
      "Epoch 178/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6127 - accuracy: 0.6758\n",
      "Epoch 179/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6058 - accuracy: 0.6795\n",
      "Epoch 180/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6020 - accuracy: 0.6797\n",
      "Epoch 181/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6067 - accuracy: 0.6762\n",
      "Epoch 182/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6052 - accuracy: 0.6804\n",
      "Epoch 183/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6049 - accuracy: 0.6812\n",
      "Epoch 184/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6076 - accuracy: 0.6800\n",
      "Epoch 185/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6054 - accuracy: 0.6839\n",
      "Epoch 186/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6060 - accuracy: 0.6826\n",
      "Epoch 187/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6015 - accuracy: 0.6844\n",
      "Epoch 188/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6101 - accuracy: 0.6758\n",
      "Epoch 189/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6086 - accuracy: 0.6816\n",
      "Epoch 190/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6073 - accuracy: 0.6805\n",
      "Epoch 191/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6070 - accuracy: 0.6835\n",
      "Epoch 192/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6202 - accuracy: 0.6861\n",
      "Epoch 193/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6137 - accuracy: 0.6825\n",
      "Epoch 194/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6063 - accuracy: 0.6807\n",
      "Epoch 195/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6065 - accuracy: 0.6790\n",
      "Epoch 196/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6019 - accuracy: 0.6828\n",
      "Epoch 197/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6201 - accuracy: 0.6818\n",
      "Epoch 198/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6088 - accuracy: 0.6821\n",
      "Epoch 199/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6131 - accuracy: 0.6839\n",
      "Epoch 200/200\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.5997 - accuracy: 0.6868\n"
     ]
    }
   ],
   "source": [
    "epochs_hist = classifier.fit(X_resampled, y_resampled , epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "probabilities_teste = classifier.predict(X_resampled)\n",
    "\n",
    "\n",
    "predicted_probabilities_positive_class = probabilities_teste[:, 0]\n",
    "\n",
    "\n",
    "predicted_labels = (probabilities_teste > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35494614],\n",
       "       [0.7783935 ],\n",
       "       [0.35494614],\n",
       "       ...,\n",
       "       [0.5244359 ],\n",
       "       [0.39627373],\n",
       "       [0.7356435 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_hist.history['loss'])\n",
    "plt.title('Model Loss Progress During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training and Validation Loss')\n",
    "plt.legend(['Training Loss']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nm_prop_oportunidade</th>\n",
       "      <th>convertido</th>\n",
       "      <th>probabilidade_conversao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adryson pinto freitas</td>\n",
       "      <td>S</td>\n",
       "      <td>0.676156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ediane rosa</td>\n",
       "      <td>S</td>\n",
       "      <td>0.354946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fabiano martins werutsky</td>\n",
       "      <td>S</td>\n",
       "      <td>0.527610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>felipe pedroso alves</td>\n",
       "      <td>S</td>\n",
       "      <td>0.354946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>juliana westphalen gonÃ§alves</td>\n",
       "      <td>N</td>\n",
       "      <td>0.531837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>matheus homrich</td>\n",
       "      <td>S</td>\n",
       "      <td>0.354946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>michelle costa malta</td>\n",
       "      <td>N</td>\n",
       "      <td>0.354946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rafaela de sousa paonessa loureiro</td>\n",
       "      <td>S</td>\n",
       "      <td>0.727105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 nm_prop_oportunidade convertido  probabilidade_conversao\n",
       "0               adryson pinto freitas          S                 0.676156\n",
       "1                         ediane rosa          S                 0.354946\n",
       "2            fabiano martins werutsky          S                 0.527610\n",
       "3                felipe pedroso alves          S                 0.354946\n",
       "4        juliana westphalen gonÃ§alves          N                 0.531837\n",
       "5                     matheus homrich          S                 0.354946\n",
       "6                michelle costa malta          N                 0.354946\n",
       "7  rafaela de sousa paonessa loureiro          S                 0.727105"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probabilities_teste = classifier.predict(X_test_final)\n",
    "\n",
    "predicted_probabilities = probabilities_teste.flatten()\n",
    "\n",
    "\n",
    "df_temporario_teste = pd.DataFrame({\n",
    "    'nm_prop_oportunidade': x_teste_df['nm_prop_oportunidade'].values,\n",
    "    'convertido': y_teste.values,\n",
    "    'probabilidade_conversao': predicted_probabilities\n",
    "})\n",
    "\n",
    "\n",
    "df_temporario_teste = df_temporario_teste.drop_duplicates(subset=['nm_prop_oportunidade', 'convertido'])\n",
    "df_resultados_teste = df_temporario_teste.groupby('nm_prop_oportunidade', as_index=False).agg({\n",
    "    'convertido': 'first',\n",
    "    'probabilidade_conversao': 'mean'\n",
    "})\n",
    "\n",
    "\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df_resultados_teste)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados_teste.to_csv(\"classificacao_tensorflow.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnm_prop_oportunidade\\tconvertido\\tprobabilidade_conversao\\n0\\tadryson pinto freitas\\tS\\t0.495354\\n1\\tediane rosa\\tS\\t0.946118\\n2\\tfabiano martins werutsky\\tS\\t0.546198\\n3\\tfelipe pedroso alves\\tS\\t0.925496\\n4\\tjuliana westphalen gonÃ§alves\\tN\\t0.388855\\n5\\tmatheus homrich\\tS\\t0.822305\\n6\\tmichelle costa malta\\tN\\t0.819763\\n7\\trafaela de sousa paonessa loureiro\\tS\\t0.765156'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "nm_prop_oportunidade\tconvertido\tprobabilidade_conversao\n",
    "0\tadryson pinto freitas\tS\t0.495354\n",
    "1\tediane rosa\tS\t0.946118\n",
    "2\tfabiano martins werutsky\tS\t0.546198\n",
    "3\tfelipe pedroso alves\tS\t0.925496\n",
    "4\tjuliana westphalen gonÃ§alves\tN\t0.388855\n",
    "5\tmatheus homrich\tS\t0.822305\n",
    "6\tmichelle costa malta\tN\t0.819763\n",
    "7\trafaela de sousa paonessa loureiro\tS\t0.765156'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnm_prop_oportunidade\\tconvertido\\tprobabilidade_conversao\\n0\\tadryson pinto freitas\\tS\\t0.707530\\n1\\tediane rosa\\tS\\t0.361255\\n2\\tfabiano martins werutsky\\tS\\t0.492400\\n3\\tfelipe pedroso alves\\tS\\t0.373291\\n4\\tjuliana westphalen gonÃ§alves\\tN\\t0.555003\\n5\\tmatheus homrich\\tS\\t0.397562\\n6\\tmichelle costa malta\\tN\\t0.465311\\n7\\trafaela de sousa paonessa loureiro\\tS\\t0.700739'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "nm_prop_oportunidade\tconvertido\tprobabilidade_conversao\n",
    "0\tadryson pinto freitas\tS\t0.707530\n",
    "1\tediane rosa\tS\t0.361255\n",
    "2\tfabiano martins werutsky\tS\t0.492400\n",
    "3\tfelipe pedroso alves\tS\t0.373291\n",
    "4\tjuliana westphalen gonÃ§alves\tN\t0.555003\n",
    "5\tmatheus homrich\tS\t0.397562\n",
    "6\tmichelle costa malta\tN\t0.465311\n",
    "7\trafaela de sousa paonessa loureiro\tS\t0.700739'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
