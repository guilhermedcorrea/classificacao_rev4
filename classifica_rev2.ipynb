{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_treino = pd.read_csv(r\"D:\\pipeline_dados\\data_raw\\base_orcamentos_treino.csv\")\n",
    "x_teste_df = pd.read_csv(r\"D:\\pipeline_dados\\base_orcamentos_nov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_treino = base_treino[base_treino['proprietario']=='zzzzzzzXzzXzzzzzXzzzzzzzzXzzzzzzzz']\n",
    "\n",
    "#x_teste_df = x_teste_df[x_teste_df['proprietario'] == 'zzzzzzzXzzXzzzzzXzzzzzzzzXzzzzzzzz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#x_teste_df = x_teste_df[x_teste_df['proprietario'] == 'zzzzzzzXzzXzzzzzXzzzzzzzzXzzzzzzzz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nm_prop_oportunidade,dias_desejo,dias_em_casa\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_quote</th>\n",
       "      <th>dt_criacao</th>\n",
       "      <th>dias_desejo</th>\n",
       "      <th>dias_em_casa</th>\n",
       "      <th>ds_tipo_obra</th>\n",
       "      <th>nm_prop_oportunidade</th>\n",
       "      <th>proprietario</th>\n",
       "      <th>promocional</th>\n",
       "      <th>convertido</th>\n",
       "      <th>tipo_loja</th>\n",
       "      <th>...</th>\n",
       "      <th>amb_outros</th>\n",
       "      <th>revestimento</th>\n",
       "      <th>officina</th>\n",
       "      <th>loucas_metais</th>\n",
       "      <th>arg_rejunte</th>\n",
       "      <th>categ_outros</th>\n",
       "      <th>vl_frete</th>\n",
       "      <th>vlr_orcamento</th>\n",
       "      <th>convertidos</th>\n",
       "      <th>nao_convertidos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0Q03s000000GRoxCAG</td>\n",
       "      <td>2022-06-09</td>\n",
       "      <td>203</td>\n",
       "      <td>534</td>\n",
       "      <td>Nova Obra</td>\n",
       "      <td>leticia silva de arruda</td>\n",
       "      <td>zzzzzzzXzzzzzXzzXzzzzzz</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>Tradicional A</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>153.33</td>\n",
       "      <td>76444.94</td>\n",
       "      <td>412</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0Q03s000000GRsGCAW</td>\n",
       "      <td>2022-06-09</td>\n",
       "      <td>11</td>\n",
       "      <td>534</td>\n",
       "      <td>Nova Obra</td>\n",
       "      <td>leticia silva de arruda</td>\n",
       "      <td>zzzzzzzXzzzzzXzzXzzzzzz</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>Tradicional A</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.67</td>\n",
       "      <td>64.80</td>\n",
       "      <td>412</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0Q03s000000GRwXCAW</td>\n",
       "      <td>2022-06-09</td>\n",
       "      <td>15</td>\n",
       "      <td>534</td>\n",
       "      <td>Nova Obra</td>\n",
       "      <td>fabiano martins werutsky</td>\n",
       "      <td>zzzzzzzXzzzzzzzXzzzzzzzz</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>Tradicional A</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266.67</td>\n",
       "      <td>14763.62</td>\n",
       "      <td>343</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0Q03s000000GS0UCAW</td>\n",
       "      <td>2022-06-09</td>\n",
       "      <td>30</td>\n",
       "      <td>534</td>\n",
       "      <td>Nova Obra</td>\n",
       "      <td>leticia silva de arruda</td>\n",
       "      <td>zzzzzzzXzzzzzXzzXzzzzzz</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>Tradicional A</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>66.67</td>\n",
       "      <td>1301.09</td>\n",
       "      <td>412</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0Q03s000000GS1cCAG</td>\n",
       "      <td>2022-06-09</td>\n",
       "      <td>29</td>\n",
       "      <td>534</td>\n",
       "      <td>Reforma</td>\n",
       "      <td>rafaela de sousa paonessa loureiro</td>\n",
       "      <td>zzzzzzzXzzXzzzzzXzzzzzzzzXzzzzzzzz</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>Tradicional A</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83.33</td>\n",
       "      <td>3276.30</td>\n",
       "      <td>342</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5592</th>\n",
       "      <td>0Q03s000001mURcCAM</td>\n",
       "      <td>2023-10-17</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>Nova Obra</td>\n",
       "      <td>fabiano martins werutsky</td>\n",
       "      <td>zzzzzzzXzzzzzzzXzzzzzzzz</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>Tradicional A</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>93.33</td>\n",
       "      <td>1905.18</td>\n",
       "      <td>343</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5593</th>\n",
       "      <td>0Q03s000001mUX1CAM</td>\n",
       "      <td>2023-10-17</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>Reforma</td>\n",
       "      <td>patricia agnes</td>\n",
       "      <td>zzzzzzzzXzzzzz</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>Tradicional A</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>131.27</td>\n",
       "      <td>348</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5594</th>\n",
       "      <td>0Q03s000001mUdiCAE</td>\n",
       "      <td>2023-10-17</td>\n",
       "      <td>52</td>\n",
       "      <td>39</td>\n",
       "      <td>Nova Obra</td>\n",
       "      <td>juliana westphalen gonçalves</td>\n",
       "      <td>zzzzzzzXzzzzzzzzzzXzzzzzzzzz</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>Tradicional A</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>493.33</td>\n",
       "      <td>35609.59</td>\n",
       "      <td>488</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>0Q03s000001mUh6CAE</td>\n",
       "      <td>2023-10-17</td>\n",
       "      <td>196</td>\n",
       "      <td>39</td>\n",
       "      <td>Reforma</td>\n",
       "      <td>matheus homrich</td>\n",
       "      <td>zzzzzzzXzzzzzzz</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>Tradicional A</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>576.45</td>\n",
       "      <td>27856.07</td>\n",
       "      <td>184</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5596</th>\n",
       "      <td>0Q03s000001mUlNCAU</td>\n",
       "      <td>2023-10-17</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>Nova Obra</td>\n",
       "      <td>fabiano martins werutsky</td>\n",
       "      <td>zzzzzzzXzzzzzzzXzzzzzzzz</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>Tradicional A</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.36</td>\n",
       "      <td>343</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5597 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_quote  dt_criacao  dias_desejo  dias_em_casa ds_tipo_obra  \\\n",
       "0     0Q03s000000GRoxCAG  2022-06-09          203           534    Nova Obra   \n",
       "1     0Q03s000000GRsGCAW  2022-06-09           11           534    Nova Obra   \n",
       "2     0Q03s000000GRwXCAW  2022-06-09           15           534    Nova Obra   \n",
       "3     0Q03s000000GS0UCAW  2022-06-09           30           534    Nova Obra   \n",
       "4     0Q03s000000GS1cCAG  2022-06-09           29           534      Reforma   \n",
       "...                  ...         ...          ...           ...          ...   \n",
       "5592  0Q03s000001mURcCAM  2023-10-17           24            39    Nova Obra   \n",
       "5593  0Q03s000001mUX1CAM  2023-10-17            1            39      Reforma   \n",
       "5594  0Q03s000001mUdiCAE  2023-10-17           52            39    Nova Obra   \n",
       "5595  0Q03s000001mUh6CAE  2023-10-17          196            39      Reforma   \n",
       "5596  0Q03s000001mUlNCAU  2023-10-17            3            39    Nova Obra   \n",
       "\n",
       "                    nm_prop_oportunidade                        proprietario  \\\n",
       "0                leticia silva de arruda             zzzzzzzXzzzzzXzzXzzzzzz   \n",
       "1                leticia silva de arruda             zzzzzzzXzzzzzXzzXzzzzzz   \n",
       "2               fabiano martins werutsky            zzzzzzzXzzzzzzzXzzzzzzzz   \n",
       "3                leticia silva de arruda             zzzzzzzXzzzzzXzzXzzzzzz   \n",
       "4     rafaela de sousa paonessa loureiro  zzzzzzzXzzXzzzzzXzzzzzzzzXzzzzzzzz   \n",
       "...                                  ...                                 ...   \n",
       "5592            fabiano martins werutsky            zzzzzzzXzzzzzzzXzzzzzzzz   \n",
       "5593                      patricia agnes                      zzzzzzzzXzzzzz   \n",
       "5594        juliana westphalen gonçalves        zzzzzzzXzzzzzzzzzzXzzzzzzzzz   \n",
       "5595                     matheus homrich                     zzzzzzzXzzzzzzz   \n",
       "5596            fabiano martins werutsky            zzzzzzzXzzzzzzzXzzzzzzzz   \n",
       "\n",
       "     promocional convertido      tipo_loja  ... amb_outros revestimento  \\\n",
       "0              S          N  Tradicional A  ...          S            7   \n",
       "1              S          S  Tradicional A  ...          N            1   \n",
       "2              S          N  Tradicional A  ...          S            1   \n",
       "3              S          S  Tradicional A  ...          S            1   \n",
       "4              S          N  Tradicional A  ...          S            0   \n",
       "...          ...        ...            ...  ...        ...          ...   \n",
       "5592           S          N  Tradicional A  ...          S            1   \n",
       "5593           S          S  Tradicional A  ...          S            1   \n",
       "5594           S          N  Tradicional A  ...          S            8   \n",
       "5595           S          S  Tradicional A  ...          S            7   \n",
       "5596           S          S  Tradicional A  ...          N            1   \n",
       "\n",
       "     officina loucas_metais arg_rejunte categ_outros vl_frete vlr_orcamento  \\\n",
       "0           2             0           8            0   153.33      76444.94   \n",
       "1           0             0           0            0    26.67         64.80   \n",
       "2           0             0           0            0   266.67      14763.62   \n",
       "3           0             0           4            0    66.67       1301.09   \n",
       "4           0            10           0            0    83.33       3276.30   \n",
       "...       ...           ...         ...          ...      ...           ...   \n",
       "5592        0             0           4            0    93.33       1905.18   \n",
       "5593        0             0           0            0    60.00        131.27   \n",
       "5594        0             0          10            0   493.33      35609.59   \n",
       "5595        4             0          18            0   576.45      27856.07   \n",
       "5596        0             0           0            0     0.00         84.36   \n",
       "\n",
       "     convertidos nao_convertidos  \n",
       "0            412             330  \n",
       "1            412             330  \n",
       "2            343             438  \n",
       "3            412             330  \n",
       "4            342             406  \n",
       "...          ...             ...  \n",
       "5592         343             438  \n",
       "5593         348             503  \n",
       "5594         488             538  \n",
       "5595         184             197  \n",
       "5596         343             438  \n",
       "\n",
       "[5597 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TESTE REV 1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing date column: dt_criacao\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "base_treino = pd.read_csv(r\"D:\\pipeline_dados\\data_raw\\base_orcamentos_treino.csv\")\n",
    "x_teste_df = pd.read_csv(r\"D:\\pipeline_dados\\base_orcamentos_nov.csv\")\n",
    "\n",
    "y_teste = x_teste_df['convertido']\n",
    "x_teste_df = x_teste_df.drop(['convertido', 'id_quote'], axis=1)\n",
    "\n",
    "categoricos = ['ds_tipo_obra', 'nm_prop_oportunidade', 'proprietario', 'promocional', 'tipo_loja',\n",
    "               'banheiro', 'toda_casa', 'cozinha', 'area_externa', 'itens_assentamento', 'sala',\n",
    "               'piscina', 'area_servico', 'garagem', 'dormitorio', 'varanda', 'escada', 'amb_outros']\n",
    "\n",
    "date_column = 'dt_criacao'\n",
    "\n",
    "if date_column in base_treino.columns:\n",
    "    print(f\"Removing date column: {date_column}\")\n",
    "    base_treino = base_treino.drop(date_column, axis=1, errors='ignore')\n",
    "    if date_column in categoricos:\n",
    "        categoricos.remove(date_column)\n",
    "else:\n",
    "    print(f\"Date column '{date_column}' not found in the training data.\")\n",
    "\n",
    "if date_column in x_teste_df.columns:\n",
    "    x_teste_df = x_teste_df.drop(date_column, axis=1, errors='ignore')\n",
    "    if date_column in categoricos:\n",
    "        categoricos.remove(date_column)\n",
    "else:\n",
    "    print(f\"Date column '{date_column}' not found in the test data.\")\n",
    "\n",
    "X = base_treino.drop(['convertido'], axis=1, errors='ignore')\n",
    "y = base_treino['convertido']\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "encoder = OneHotEncoder(drop='if_binary', handle_unknown='ignore')\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(X[categoricos]).toarray(),\n",
    "                          columns=encoder.get_feature_names_out(categoricos))\n",
    "\n",
    "X_final = pd.concat([X.drop(categoricos, axis=1), X_encoded], axis=1)\n",
    "\n",
    "X_test_encoded = pd.DataFrame(encoder.transform(x_teste_df[categoricos]).toarray(),\n",
    "                               columns=encoder.get_feature_names_out(categoricos))\n",
    "X_test_final = pd.concat([x_teste_df.drop('id_quote', axis=1, errors='ignore'), X_test_encoded], axis=1).drop(categoricos, axis=1).fillna(0)\n",
    "\n",
    "X = X.select_dtypes(exclude=['datetime64[ns]']) \n",
    "\n",
    "numeric_columns = X_final.select_dtypes(include=[np.number]).columns\n",
    "var_threshold = 0.05\n",
    "selector = VarianceThreshold(threshold=var_threshold)\n",
    "X_high_variance = selector.fit_transform(X_final[numeric_columns])\n",
    "\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "X_resampled = X_high_variance\n",
    "X_test_final = X_test_final.iloc[:, selected_feature_indices]\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_resampled, y)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "}\n",
    "\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(xgb_classifier, param_grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "modelo_xgb = XGBClassifier(**best_params)\n",
    "\n",
    "modelo_xgb.fit(X_resampled, y_resampled)\n",
    "\n",
    "probabilidades_teste = modelo_xgb.predict_proba(X_test_final)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades_teste = modelo_xgb.predict_proba(X_test_final)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nm_prop_oportunidade</th>\n",
       "      <th>convertido</th>\n",
       "      <th>probabilidade_conversao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adryson pinto freitas</td>\n",
       "      <td>S</td>\n",
       "      <td>0.495354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ediane rosa</td>\n",
       "      <td>S</td>\n",
       "      <td>0.946118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fabiano martins werutsky</td>\n",
       "      <td>S</td>\n",
       "      <td>0.546198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>felipe pedroso alves</td>\n",
       "      <td>S</td>\n",
       "      <td>0.925496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>juliana westphalen gonçalves</td>\n",
       "      <td>N</td>\n",
       "      <td>0.388855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>matheus homrich</td>\n",
       "      <td>S</td>\n",
       "      <td>0.822305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>michelle costa malta</td>\n",
       "      <td>N</td>\n",
       "      <td>0.819763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rafaela de sousa paonessa loureiro</td>\n",
       "      <td>S</td>\n",
       "      <td>0.765156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 nm_prop_oportunidade convertido  probabilidade_conversao\n",
       "0               adryson pinto freitas          S                 0.495354\n",
       "1                         ediane rosa          S                 0.946118\n",
       "2            fabiano martins werutsky          S                 0.546198\n",
       "3                felipe pedroso alves          S                 0.925496\n",
       "4        juliana westphalen gonçalves          N                 0.388855\n",
       "5                     matheus homrich          S                 0.822305\n",
       "6                michelle costa malta          N                 0.819763\n",
       "7  rafaela de sousa paonessa loureiro          S                 0.765156"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_temporario_teste = pd.DataFrame({\n",
    "    'nm_prop_oportunidade': x_teste_df.loc[x_teste_df.index, 'nm_prop_oportunidade'],\n",
    "    'convertido': y_teste,\n",
    "    'probabilidade_conversao': probabilidades_teste\n",
    "   \n",
    "   \n",
    "})\n",
    "\n",
    "\n",
    "df_temporario_teste = df_temporario_teste.drop_duplicates(subset=['nm_prop_oportunidade', 'convertido'])\n",
    "df_resultados_teste = df_temporario_teste.groupby('nm_prop_oportunidade', as_index=False).agg({\n",
    "    'convertido': 'first',\n",
    "    'probabilidade_conversao': 'mean'\n",
    "})\n",
    "\n",
    "\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df_resultados_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados_teste.to_csv(\"testeprevisao.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TESTE REV 2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"TESTE REV 2\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_treino = pd.read_csv(r\"D:\\pipeline_dados\\data_raw\\base_orcamentos_treino.csv\")\n",
    "x_teste_df = pd.read_csv(r\"D:\\pipeline_dados\\base_orcamentos_nov.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removendo coluna de data: dt_criacao\n",
      "Removendo coluna de data: dt_criacao\n",
      "Métricas no Conjunto de Treinamento:\n",
      "Precisão:  0.7739380849532037\n",
      "Revocação:  0.7514854945823138\n",
      "Pontuação F1:  0.7625465508068806\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "base_treino = pd.read_csv(r\"D:\\pipeline_dados\\data_raw\\base_orcamentos_treino.csv\")\n",
    "x_teste_df = pd.read_csv(r\"D:\\pipeline_dados\\base_orcamentos_nov.csv\")\n",
    "\n",
    "\n",
    "date_column = 'dt_criacao'\n",
    "for df in [base_treino, x_teste_df]:\n",
    "    if date_column in df.columns:\n",
    "        print(f\"Removendo coluna de data: {date_column}\")\n",
    "        df.drop(date_column, axis=1, errors='ignore', inplace=True)\n",
    "\n",
    "\n",
    "categoricos = ['ds_tipo_obra', 'nm_prop_oportunidade', 'proprietario', 'promocional', 'tipo_loja',\n",
    "               'banheiro', 'toda_casa', 'cozinha', 'area_externa', 'itens_assentamento', 'sala',\n",
    "               'piscina', 'area_servico', 'garagem', 'dormitorio', 'varanda', 'escada', 'amb_outros']\n",
    "\n",
    "\n",
    "y = base_treino['convertido']\n",
    "\n",
    "\n",
    "label_encoder_y = LabelEncoder()\n",
    "y = label_encoder_y.fit_transform(y)\n",
    "\n",
    "\n",
    "X = base_treino.drop([date_column], axis=1, errors='ignore')\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(drop='if_binary', handle_unknown='ignore')\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(X[categoricos]).toarray(),\n",
    "                          columns=encoder.get_feature_names_out(categoricos))\n",
    "X_final = pd.concat([X.drop(categoricos, axis=1), X_encoded], axis=1)\n",
    "\n",
    "\n",
    "numeric_columns = X_final.select_dtypes(include=[np.number]).columns\n",
    "var_threshold = 0.20\n",
    "selector = VarianceThreshold(threshold=var_threshold)\n",
    "X_high_variance = selector.fit_transform(X_final[numeric_columns])\n",
    "\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "X_high_variance_columns = X_final.columns[selected_feature_indices]\n",
    "\n",
    "\n",
    "X_high_variance = pd.DataFrame(X_high_variance, columns=X_high_variance_columns)\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_high_variance, y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "}\n",
    "\n",
    "\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(xgb_classifier, param_grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "\n",
    "modelo_xgb = XGBClassifier(**best_params)\n",
    "\n",
    "\n",
    "modelo_xgb.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "calibrated_model = CalibratedClassifierCV(modelo_xgb, method='sigmoid', cv='prefit')\n",
    "calibrated_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "y_pred_train = calibrated_model.predict(X_resampled)\n",
    "print(\"Métricas no Conjunto de Treinamento:\")\n",
    "print(\"Precisão: \", precision_score(y_resampled, y_pred_train))\n",
    "print(\"Revocação: \", recall_score(y_resampled, y_pred_train))\n",
    "print(\"Pontuação F1: \", f1_score(y_resampled, y_pred_train))\n",
    "\n",
    "\n",
    "X_test_encoded = pd.DataFrame(encoder.transform(x_teste_df[categoricos]).toarray(),\n",
    "                              columns=encoder.get_feature_names_out(categoricos))\n",
    "X_test_final = pd.concat([x_teste_df.drop(categoricos, axis=1), X_test_encoded], axis=1)\n",
    "\n",
    "\n",
    "numeric_columns_test = X_test_final.select_dtypes(include=[np.number]).columns\n",
    "X_test_high_variance = selector.transform(X_test_final[numeric_columns_test])\n",
    "\n",
    "\n",
    "X_test_high_variance = pd.DataFrame(X_test_high_variance, columns=X_high_variance_columns)\n",
    "\n",
    "\n",
    "probabilidades_teste = calibrated_model.predict_proba(X_test_high_variance)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nm_prop_oportunidade</th>\n",
       "      <th>convertido</th>\n",
       "      <th>id_quote</th>\n",
       "      <th>probabilidade_conversao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adryson pinto freitas</td>\n",
       "      <td>S</td>\n",
       "      <td>0Q03s000000T3ACCA0</td>\n",
       "      <td>0.308874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ediane rosa</td>\n",
       "      <td>S</td>\n",
       "      <td>0Q0SG0000001dsB0AQ</td>\n",
       "      <td>0.913264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fabiano martins werutsky</td>\n",
       "      <td>S</td>\n",
       "      <td>0Q03s000000T1SnCAK</td>\n",
       "      <td>0.476274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>felipe pedroso alves</td>\n",
       "      <td>S</td>\n",
       "      <td>0Q0SG0000003JR80AM</td>\n",
       "      <td>0.865123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>juliana westphalen gonçalves</td>\n",
       "      <td>N</td>\n",
       "      <td>0Q03s000000T1zXCAS</td>\n",
       "      <td>0.452615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>matheus homrich</td>\n",
       "      <td>S</td>\n",
       "      <td>0Q03s000000T2EDCA0</td>\n",
       "      <td>0.643881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>michelle costa malta</td>\n",
       "      <td>N</td>\n",
       "      <td>0Q0SG0000003voA0AQ</td>\n",
       "      <td>0.905814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rafaela de sousa paonessa loureiro</td>\n",
       "      <td>S</td>\n",
       "      <td>0Q03s000000T1aNCAS</td>\n",
       "      <td>0.613912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 nm_prop_oportunidade convertido            id_quote  \\\n",
       "0               adryson pinto freitas          S  0Q03s000000T3ACCA0   \n",
       "1                         ediane rosa          S  0Q0SG0000001dsB0AQ   \n",
       "2            fabiano martins werutsky          S  0Q03s000000T1SnCAK   \n",
       "3                felipe pedroso alves          S  0Q0SG0000003JR80AM   \n",
       "4        juliana westphalen gonçalves          N  0Q03s000000T1zXCAS   \n",
       "5                     matheus homrich          S  0Q03s000000T2EDCA0   \n",
       "6                michelle costa malta          N  0Q0SG0000003voA0AQ   \n",
       "7  rafaela de sousa paonessa loureiro          S  0Q03s000000T1aNCAS   \n",
       "\n",
       "   probabilidade_conversao  \n",
       "0                 0.308874  \n",
       "1                 0.913264  \n",
       "2                 0.476274  \n",
       "3                 0.865123  \n",
       "4                 0.452615  \n",
       "5                 0.643881  \n",
       "6                 0.905814  \n",
       "7                 0.613912  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_temporario_teste = pd.DataFrame({\n",
    "    'nm_prop_oportunidade': x_teste_df.loc[x_teste_df.index, 'nm_prop_oportunidade'],\n",
    "    'convertido': y_teste,\n",
    "    'probabilidade_conversao': probabilidades_teste,\n",
    "    'id_quote':x_teste_df.loc[x_teste_df.index, 'id_quote']\n",
    "})\n",
    "\n",
    "\n",
    "df_temporario_teste = df_temporario_teste.drop_duplicates(subset=['nm_prop_oportunidade', 'convertido','id_quote'])\n",
    "df_resultados_teste = df_temporario_teste.groupby('nm_prop_oportunidade', as_index=False).agg({\n",
    "    'convertido': 'first',\n",
    "    'id_quote':'first',\n",
    "    'probabilidade_conversao': 'mean'\n",
    "})\n",
    "\n",
    "\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df_resultados_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados_teste.to_csv(\"testeprevisao.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date column 'dt_criacao' not found in the categorical columns list.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\pipeline_dados\\classifica_rev2.ipynb Cell 15\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/pipeline_dados/classifica_rev2.ipynb#X16sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m smote \u001b[39m=\u001b[39m SMOTE(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/pipeline_dados/classifica_rev2.ipynb#X16sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m X_resampled, y_resampled \u001b[39m=\u001b[39m smote\u001b[39m.\u001b[39mfit_resample(X_high_variance, y)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/pipeline_dados/classifica_rev2.ipynb#X16sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m X_resampled_columns \u001b[39m=\u001b[39m X_high_variance\u001b[39m.\u001b[39;49mcolumns  \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/pipeline_dados/classifica_rev2.ipynb#X16sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m X_resampled \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(X_resampled, columns\u001b[39m=\u001b[39mX_resampled_columns)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/pipeline_dados/classifica_rev2.ipynb#X16sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m common_features \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(X_resampled\u001b[39m.\u001b[39mcolumns) \u001b[39m&\u001b[39m \u001b[39mset\u001b[39m(x_teste_df_encoded\u001b[39m.\u001b[39mcolumns)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "base_treino = pd.read_csv(r\"D:\\pipeline_dados\\data_raw\\base_orcamentos_treino.csv\")\n",
    "x_teste_df = pd.read_csv(r\"D:\\pipeline_dados\\base_orcamentos_nov.csv\")\n",
    "\n",
    "\n",
    "y_teste = x_teste_df['convertido']\n",
    "x_teste_df = x_teste_df.drop('convertido', axis=1)\n",
    "\n",
    "\n",
    "categoricos = ['ds_tipo_obra', 'nm_prop_oportunidade', 'proprietario', 'promocional', 'tipo_loja',\n",
    "               'banheiro', 'toda_casa', 'cozinha', 'area_externa', 'itens_assentamento', 'sala',\n",
    "               'piscina', 'area_servico', 'garagem', 'dormitorio', 'varanda', 'escada', 'amb_outros']\n",
    "date_column = 'dt_criacao'\n",
    "\n",
    "\n",
    "date_column_stripped = date_column.strip()\n",
    "if date_column_stripped in categoricos:\n",
    "    print(f\"Removing date column: {date_column_stripped}\")\n",
    "    base_treino = base_treino.drop(date_column_stripped, axis=1)\n",
    "    x_teste_df = x_teste_df.drop(date_column_stripped, axis=1)\n",
    "    categoricos.remove(date_column_stripped)\n",
    "else:\n",
    "    print(f\"Date column '{date_column_stripped}' not found in the categorical columns list.\")\n",
    "\n",
    "\n",
    "if date_column in base_treino.columns:\n",
    "    base_treino[date_column] = pd.to_datetime(base_treino[date_column])\n",
    "    x_teste_df[date_column] = pd.to_datetime(x_teste_df[date_column])\n",
    "\n",
    "\n",
    "X_no_date = base_treino.drop(['convertido', 'id_quote', date_column], axis=1)\n",
    "X_date_only = pd.DataFrame(base_treino[date_column])\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(drop='if_binary', handle_unknown='ignore')\n",
    "df_encoded_train = pd.DataFrame(encoder.fit_transform(X_no_date[categoricos]).toarray(),\n",
    "                                columns=encoder.get_feature_names_out(categoricos))\n",
    "df_final_train = pd.concat([X_date_only, df_encoded_train], axis=1)\n",
    "\n",
    "\n",
    "df_encoded_test = pd.DataFrame(encoder.transform(x_teste_df[categoricos]).toarray(),\n",
    "                               columns=encoder.get_feature_names_out(categoricos))\n",
    "x_teste_df_encoded = pd.concat([x_teste_df[date_column].astype('int64'), df_encoded_test], axis=1)\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(base_treino['convertido'])\n",
    "\n",
    "var_threshold = 0.05\n",
    "selector = VarianceThreshold(threshold=var_threshold)\n",
    "X_high_variance = selector.fit_transform(df_final_train.drop([date_column], axis=1))\n",
    "\n",
    "if X_high_variance.shape[1] == 0:\n",
    "    raise ValueError(f\"No feature in X meets the variance threshold {var_threshold:.5f}\")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_high_variance, y)\n",
    "\n",
    "\n",
    "X_resampled_columns = X_high_variance.columns  \n",
    "X_resampled = pd.DataFrame(X_resampled, columns=X_resampled_columns)\n",
    "\n",
    "\n",
    "common_features = set(X_resampled.columns) & set(x_teste_df_encoded.columns)\n",
    "X_resampled = X_resampled[common_features]\n",
    "x_teste_df_encoded = x_teste_df_encoded[common_features]\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "}\n",
    "\n",
    "grad_boost = GradientBoostingClassifier()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(grad_boost, param_grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "modelo_grad_boost = GradientBoostingClassifier(**best_params)\n",
    "modelo_grad_boost.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "probabilidades_teste = modelo_grad_boost.predict_proba(x_teste_df_encoded)[:, 1]\n",
    "\n",
    "\n",
    "df_temporario_teste = pd.DataFrame({\n",
    "    'nm_prop_oportunidade': x_teste_df.loc[x_teste_df.index, 'nm_prop_oportunidade'],\n",
    "    'convertido': y_teste,\n",
    "    'probabilidade_conversao': probabilidades_teste\n",
    "})\n",
    "\n",
    "\n",
    "df_temporario_teste = df_temporario_teste.drop_duplicates(subset=['nm_prop_oportunidade', 'convertido'])\n",
    "df_resultados_teste = df_temporario_teste.groupby('nm_prop_oportunidade', as_index=False).agg({\n",
    "    'convertido': 'first',\n",
    "    'probabilidade_conversao': 'mean'\n",
    "})\n",
    "\n",
    "\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df_resultados_teste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping date column:\n",
      "Index(['dias_desejo', 'dias_em_casa', 'ds_tipo_obra', 'nm_prop_oportunidade',\n",
      "       'proprietario', 'promocional', 'tipo_loja', 'banheiro', 'toda_casa',\n",
      "       'cozinha', 'area_externa', 'itens_assentamento', 'sala', 'piscina',\n",
      "       'area_servico', 'garagem', 'dormitorio', 'varanda', 'escada',\n",
      "       'amb_outros', 'revestimento', 'officina', 'loucas_metais',\n",
      "       'arg_rejunte', 'categ_outros', 'vl_frete', 'vlr_orcamento',\n",
      "       'convertidos', 'nao_convertidos'],\n",
      "      dtype='object')\n",
      "Columns after one-hot encoding:\n",
      "Index(['ds_tipo_obra_Nova Obra', 'ds_tipo_obra_Reforma', 'ds_tipo_obra_nan',\n",
      "       'nm_prop_oportunidade_adryson pinto freitas',\n",
      "       'nm_prop_oportunidade_ana paula goncalves lemos',\n",
      "       'nm_prop_oportunidade_bruno schmelzer de souza',\n",
      "       'nm_prop_oportunidade_claudia marina silva',\n",
      "       'nm_prop_oportunidade_dara jenifer de jesus',\n",
      "       'nm_prop_oportunidade_ediane rosa',\n",
      "       'nm_prop_oportunidade_fabiano martins werutsky',\n",
      "       'nm_prop_oportunidade_juliana westphalen gonçalves',\n",
      "       'nm_prop_oportunidade_leticia silva de arruda',\n",
      "       'nm_prop_oportunidade_luis roberto da silva ferreira junior',\n",
      "       'nm_prop_oportunidade_matheus homrich',\n",
      "       'nm_prop_oportunidade_maurício padilha',\n",
      "       'nm_prop_oportunidade_michelle costa malta',\n",
      "       'nm_prop_oportunidade_patricia agnes',\n",
      "       'nm_prop_oportunidade_rafael kanitz de souza',\n",
      "       'nm_prop_oportunidade_rafaela de sousa paonessa loureiro',\n",
      "       'nm_prop_oportunidade_thamye mello da silva',\n",
      "       'proprietario_zzzXzzzzzXzzzzzzzzzXzzzzz',\n",
      "       'proprietario_zzzzXzzzzzzzXzzXzzzzz',\n",
      "       'proprietario_zzzzXzzzzzzzXzzXzzzzzXzzzzzzzzXzzzzzz',\n",
      "       'proprietario_zzzzzXzzzzzzzzzXzzXzzzzz', 'proprietario_zzzzzzXzzzz',\n",
      "       'proprietario_zzzzzzXzzzzzXzzXzzzzz',\n",
      "       'proprietario_zzzzzzXzzzzzzXzzXzzzzz',\n",
      "       'proprietario_zzzzzzzXzzXzzzzzXzzzzzzzzXzzzzzzzz',\n",
      "       'proprietario_zzzzzzzXzzzzzXzzXzzzzzz',\n",
      "       'proprietario_zzzzzzzXzzzzzXzzzzzzz',\n",
      "       'proprietario_zzzzzzzXzzzzzzXzzzzz', 'proprietario_zzzzzzzXzzzzzzz',\n",
      "       'proprietario_zzzzzzzXzzzzzzzXzzzzzzzz',\n",
      "       'proprietario_zzzzzzzXzzzzzzzzzzXzzzzzzzzz',\n",
      "       'proprietario_zzzzzzzzXzzzzz', 'proprietario_zzzzzzzzXzzzzzXzzzzz',\n",
      "       'proprietario_zzzzzzzzXzzzzzzz', 'promocional_S',\n",
      "       'tipo_loja_Tradicional A', 'banheiro_S', 'toda_casa_S', 'cozinha_S',\n",
      "       'area_externa_S', 'itens_assentamento_S', 'sala_S', 'piscina_S',\n",
      "       'area_servico_S', 'garagem_S', 'dormitorio_S', 'varanda_S', 'escada_S',\n",
      "       'amb_outros_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns after dropping date column:\")\n",
    "print(X_no_date.columns)\n",
    "print(\"Columns after one-hot encoding:\")\n",
    "print(df_encoded_train.columns)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
